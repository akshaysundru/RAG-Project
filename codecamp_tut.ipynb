{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c84832b8",
   "metadata": {},
   "source": [
    "Following Free Code Camps tutorial closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc658917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4ada2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is a Kalman filter\"\n",
    "document = \"Chapter 5: AR and Kalman Filters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a94756e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_str(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns number of tokens in a text string\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return encoding.encode(string), num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58bf2df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_str(question, \"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "362d0828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM, OllamaEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")\n",
    "\n",
    "query_result = embeddings.embed_query(question)\n",
    "document_result = embeddings.embed_query(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59023cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21c96f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChain is the framework for building context-aware reasoning applications'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"LangChain is the framework for building context-aware reasoning applications\"\n",
    "\n",
    "vectorstore = InMemoryVectorStore.from_texts([text],embedding=embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "retrieved_documents = retriever.invoke(\"What is LangChain?\")\n",
    "\n",
    "retrieved_documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e3e9f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.011980836, 0.00060159597, 0.01622734, -0.021190219, -0.0013888354, -0.011334282, -0.011777407, 0\n",
      "3072\n"
     ]
    }
   ],
   "source": [
    "single_vector = embeddings.embed_query(text)\n",
    "\n",
    "print(str(single_vector)[:100])\n",
    "print(len(single_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "776122c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.011980836, 0.00060159597, 0.01622734, -0.021190219, -0.0013888354, -0.011334282, -0.011777407, 0\n",
      "3072\n",
      "[-0.0060160398, 0.0022261643, 0.004709511, -0.003964905, -0.0017332155, -0.016549783, -0.004619044, \n",
      "3072\n"
     ]
    }
   ],
   "source": [
    "text2 = (\"LangGraph is a library for building stateful, multi-actor applications with LLMs\")\n",
    "\n",
    "two_vectors = embeddings.embed_documents([text, text2])\n",
    "for vector in two_vectors:\n",
    "    print(str(vector)[:100])  # Show the first 100 characters of the vector\n",
    "    print(len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c7fe479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6177236244940539\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product/(norm_vec1 * norm_vec2)\n",
    "\n",
    "similarity = cosine_similarity(query_result, document_result)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d1a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 514\n",
      "Total characters: 659\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"Lecture 1 - Basic circuit theory.pdf\")\n",
    "loader2 = PyPDFLoader(\"Lecture 7- The MOS transistors.pdf\")\n",
    "docs = loader.load()\n",
    "docs2 = loader2.load()\n",
    "\n",
    "print(f\"Total characters: {len(docs[2].page_content)}\")\n",
    "print(f\"Total characters: {len(docs2[5].page_content)}\")\n",
    "print(len(docs2))\n",
    "print(docs2[5].page_content[:500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

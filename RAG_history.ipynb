{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda8f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_ollama import OllamaLLM\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import os\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be611b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chat_memory import InSessionMemoryHistory, ChatHistory\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2030e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"llama3.2\"\n",
    "llm = OllamaLLM(model= MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319f942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs():\n",
    "    \n",
    "    document_loader = []\n",
    "\n",
    "    for root, dirs, files in os.walk(\".\"):\n",
    "        # Skip chroma_db folder\n",
    "        if \"faiss\" in root or \"git\" in root:\n",
    "            continue\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                document_loader.append(file)\n",
    "\n",
    "    return document_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0602f94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENSC3016_Course_Notes_Part_1_Electromagnetism_Transformers.pdf',\n",
       " 'ENSC3016_Course_Notes_Part_2_Electric_Machines.pdf',\n",
       " 'Electric Machinery Fundamentals Textbook -- Chapman.pdf',\n",
       " 'ENSC3016 Study Guide 1-Review of Circuit Fundamentals.pdf',\n",
       " 'Three Phase Power System Fundamentals.pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_loader = load_docs()\n",
    "document_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faa47d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model =\"sentence-transformers/all-MiniLM-L6-v2\" #embedding matrix model\n",
    "\n",
    "def embed_splitting(document_loader, embedding_model):\n",
    "    embeddings = HuggingFaceEmbeddings(model = embedding_model, encode_kwargs={'normalize_embeddings': True})\n",
    "\n",
    "    doc_store = []\n",
    "    for file in document_loader:\n",
    "        loader = PyPDFLoader(file)\n",
    "        doc = loader.load()\n",
    "        doc_store += doc\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size = 400,\n",
    "        chunk_overlap = 64\n",
    "        )\n",
    "    \n",
    "    #Make splits\n",
    "    splits = text_splitter.split_documents(doc_store)\n",
    "\n",
    "    return embeddings, splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab3bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, splits = embed_splitting(document_loader, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c62d3215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={'normalize_embeddings': True}, query_encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc527ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e552d420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FAISS index from disk...\n"
     ]
    }
   ],
   "source": [
    "dim = len(embeddings.embed_query(\"test sentence\"))\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "\n",
    "if os.path.exists(\"faiss_index\"):\n",
    "    print(\"Loading FAISS index from disk...\")\n",
    "    vector_store = FAISS.load_local(\"faiss_index\", embeddings=embeddings, allow_dangerous_deserialization=True)\n",
    "else:\n",
    "    print(\"Building FAISS index from scratch...\")\n",
    "    dim = len(embeddings.embed_query(\"test sentence\"))\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    vector_store = FAISS(\n",
    "        embedding_function=embeddings,\n",
    "        index=index,\n",
    "        docstore=InMemoryDocstore(),\n",
    "        index_to_docstore_id={},\n",
    "    )\n",
    "    vector_store.add_documents(splits)\n",
    "    vector_store.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e00f5e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the retriever object once\n",
    "semantic_retriever = vector_store.as_retriever(search_kwargs={'k': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc11b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x1085b5610>, search_kwargs={'k': 4})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b49729a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "bm25_retriever.k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d94222d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(retrievers= [semantic_retriever, bm25_retriever], weights = [0.67, 0.33], search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e76db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\n",
    "which might reference context in the chat history, formulate a standalone question \\\n",
    "which can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, ensemble_retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e623ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Explain transformers\"\n",
    "history_results = history_aware_retriever.invoke({\"input\": user_input, \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8638ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1\n",
      "Source: ENSC3016_Course_Notes_Part_1_Electromagnetism_Transformers.pdf\n",
      "Content:\n",
      "Transformer 52 \n",
      " \n",
      " \n",
      " \n",
      "   Figure 6-3 Shell-type transformers. \n",
      " \n",
      " \n",
      " \n",
      "Figure 6-4 Flux plot: shell-type transformer \n",
      " \n",
      " \n",
      "Toroidal transformers exploit the remarkable properties of toroidal coils described in section 3.6. \n",
      "Although they are more expensive than shell-type transformers, the performance is better. They are used \n",
      "in high -quality electronic equipment and for instrument transformers (see section 6.3) where \n",
      "measurement accuracy is important. Typical toroidal transformers are shown in figure 6-5. \n",
      " \n",
      "Figure 6-5 Toroidal transformers.\n",
      " \n",
      " \n",
      " \n",
      "6.2 Transformer Principle: \n",
      "The action of a transformer is most easily understood if the two coils are wound on opposite sides of a \n",
      "magnetic core, as shown in the model of figure 6 -6. This form is used for some low -cost transformers, \n",
      "but the magnetic coupling is not as good as with the shell-type construction. \n",
      " \n",
      " \n",
      "Figure 6-6  Core-type transformer \n",
      " \n",
      " \n",
      " \n",
      "Figure 6 -7 is a schematic representation of the transformer. It will be assumed that the coupling is \n",
      "perfect: the same magnetic flux  passes through each turn of each coil. The coil connected to the source \n",
      "is termed the primary, and the coil connected to the load is termed the secondary. It is usual to refer to \n",
      "the coils as windings.\n",
      "\n",
      "Document 2\n",
      "Source: ENSC3016_Course_Notes_Part_1_Electromagnetism_Transformers.pdf\n",
      "Content:\n",
      "51 Electrical Machines and Systems                                                                                                            \n",
      " \n",
      "6 Transformer \n",
      "6.1 Introduction: \n",
      "A transformer is a practical application of magnetically coupled coils. Usually the purpose is to transfer \n",
      "energy from one coil to the other, as in figure 6-1 where energy is transferred from the AC source to the \n",
      "lamp through the space between the coils. \n",
      " \n",
      "Figure 6-1 Transformer principle \n",
      "Transformers are essentially AC devices, because there has to be a change of flux to give an induced \n",
      "voltage in a coil. There are two main reasons for transferring energy in this way: \n",
      " To provide electrical isolation between the source and the load. \n",
      " To change the voltage and current levels. \n",
      "The coils are usually placed on a common magnetic core to improve the coupling. Figure 6-2 shows the \n",
      "flux plots for two coupled coils (a) without a core, (b) with an open core, (c) with a closed core \n",
      " \n",
      "Figure 6-2 Effect of a magnetic core: \n",
      "6.1.2 Practical aspects: \n",
      "The cores for high -frequency transformers are often made from magnetically soft ferrites, which are \n",
      "electrical insulators. For power frequencies, the cores are made from an iron alloy such as silicon steel.\n",
      "\n",
      "Document 3\n",
      "Source: ENSC3016_Course_Notes_Part_1_Electromagnetism_Transformers.pdf\n",
      "Content:\n",
      "𝑑𝜙\n",
      "𝑑𝑡        (6 − 3) \n",
      "𝑣2 = 𝑅2𝑖2 + 𝑁2\n",
      "𝑑𝜙\n",
      "𝑑𝑡                               (6 − 4) \n",
      "The sign difference arises from the reference directions for current in the two windings. \n",
      "If the resistances R1 and R2 are negligible, then equations 6-3 and 6-4 become: \n",
      "𝑣1 ≈ 𝑁1\n",
      "𝑑𝜙\n",
      "𝑑𝑡          (6 − 5) \n",
      "𝑣2 ≈ 𝑁2\n",
      "𝑑𝜙\n",
      "𝑑𝑡         (6 − 6) \n",
      "Dividing these equations gives the important result: \n",
      "𝑣1\n",
      "𝑣2\n",
      "≈ 𝑁1\n",
      "𝑁2\n",
      "        (6 − 7) \n",
      "Thus, the secondary voltage can be made larger or smaller than the primary voltage by changing the \n",
      "ratio of the numbers of turns on the two windings. Voltage transformation is one of the most common \n",
      "uses of transformers, on a large scale in electrical power transmission and distribution, and on a small \n",
      "scale in the power supplies for electronic equipment. \n",
      "6.2.2 Sinusoidal operation: \n",
      "If the voltage source is sinusoidal, then the core flux will also be sinusoidal, so we may put:\n",
      "\n",
      "Document 4\n",
      "Source: ENSC3016_Course_Notes_Part_1_Electromagnetism_Transformers.pdf\n",
      "Content:\n",
      "𝑽𝒔 = 𝑽𝟏 + 𝑽𝟐 = 𝟐𝑽𝟐 = 𝟐𝑽𝑳        (6 − 22) \n",
      "𝑰𝑳 = 𝑰𝟏 + 𝑰𝟐 = 𝟐𝑰𝟏 = 𝟐𝑰𝑳            (6 − 23) \n",
      "Where VL is the voltage across the load and IS is the current supplied by the source. This auto-wound \n",
      "transformer behaves as a step-down transformer with a ratio of 2:1, and the current in each winding is \n",
      "equal to half of the load current. \n",
      "An elegant application of the auto-wound transformer principle is the variable transformer, which has a \n",
      "single-layer coil wound on a toroidal core. The output is taken from a carbon brush that makes contact \n",
      "with the surface of the coil; the brush can be moved smoothly from one end of the coil to the other, thus \n",
      "varying the output voltage. Examples of variable transformers are shown in figure 6-10. \n",
      " \n",
      "     \n",
      "      Figure 6-10 Variable transformers. \n",
      " \n",
      " \n",
      " \n",
      "6.3.2 3 Phase Transformer: \n",
      "In 3 -phase systems, it is common practice to use sets of three single -phase transformers. It is also \n",
      "possible, however, to make 3 -phase transformers with three sets of windings on three limbs of a core, \n",
      "as shown in figure 6-11. \n",
      " \n",
      "Figure 6-11 3-phase transformer model\n",
      "\n",
      "Document 5\n",
      "Source: ENSC3016_Course_Notes_Part_1_Electromagnetism_Transformers.pdf\n",
      "Content:\n",
      "65 Electrical Machines and Systems                                                                                                            \n",
      "6.8 Current Transformers \n",
      "Instrument transformers are special transformers for extending the range of measur ing instruments. \n",
      "There are two basic types: voltage transformers for measuring high voltages, and current transformers \n",
      "for measuring high currents. Using transformers for voltage measurement is similar in principle to the \n",
      "ordinary use of transformers to ch ange voltage levels, so it will not be considered further. Current \n",
      "transformers, on the other hand, need special consideration. These are usually toroidal transformers with \n",
      "high-quality core material. \n",
      "Figure 6-25 shows a load connected to a source. The primary of a current transformer is in series with \n",
      "the load, and the secondary is connected to a meter \n",
      "  \n",
      "Figure 6-25 Use of a current transformer \n",
      " \n",
      " \n",
      "Equation 6-19 gives: \n",
      "𝐼𝑀 ≈ 𝑁1\n",
      "𝑁2\n",
      "𝐼𝐿     𝑜𝑟  𝐼𝐿 ≈ 𝑁1\n",
      "𝑁2\n",
      "𝐼𝑀           (6 − 53)\n",
      "\n",
      "Document 6\n",
      "Source: ENSC3016_Course_Notes_Part_1_Electromagnetism_Transformers.pdf\n",
      "Content:\n",
      "6.1.2 Practical aspects: \n",
      "The cores for high -frequency transformers are often made from magnetically soft ferrites, which are \n",
      "electrical insulators. For power frequencies, the cores are made from an iron alloy such as silicon steel. \n",
      "These materials have better magnetic properties than ferrites, but they are also electrical conductors. If \n",
      "the core were made of solid steel, currents – known as eddy currents – would be induced in the core by \n",
      "the alternating magnetic flux.  Steel transformer cores are therefore made from thin laminations, \n",
      "insulated from one another, to minimise eddy currents [1, 6]. \n",
      "Small power transformers are commonly made with the shell -type construction shown in figure 6 -3, \n",
      "where the coils are wound on the central limb of the core, and the two outer limbs provide symmetrical \n",
      "flux return paths. The centre limb is twice the width of the outer limbs because it carries twice the flux, \n",
      "as shown by the flux plot in figure 6-4.\n",
      "\n",
      "Document 7\n",
      "Source: ENSC3016_Course_Notes_Part_1_Electromagnetism_Transformers.pdf\n",
      "Content:\n",
      "31. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "Figure 6-31 E I laminations \n",
      "The center limb is twice the width of the outer limbs because it carries twice the flux, as shown by \n",
      "the flux plot in figure 6-32. \n",
      " \n",
      "Figure 6-32  Flux Plot: Shell type transformer \n",
      "The coils are wound on a bobbin that fits the center limb of the core, and the core is assembled \n",
      "by inserting E laminations alternately from each side and adding matching I laminations. \n",
      "Dimensions are chosen so that two E and two I laminations can be punched from a rectangular steel \n",
      "sheet without any waste. Current flowing in the resistance of the transformer windings will produce \n",
      "heat, which must escape through the surface of the windings. In addition, there will be power loss in \n",
      "the core, which also appears as heat. \n",
      "The power output from a given size of transformer is governed by the rate at which heat can be \n",
      "removed. Large transformers are usually cooled by circulating oil, but small transformers rely on\n"
     ]
    }
   ],
   "source": [
    "for i, doc in enumerate(history_results):\n",
    "    print(f\"\\nDocument {i+1}\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'unknown')}\")\n",
    "    print(f\"Content:\\n{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc7586a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input_prompt = \"\"\"You are an expert assistant answering based only on the provided context.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Use all relevant information above to answer the question below. If the answer isn't found in the chunks, say:\n",
    "    \"I cannot answer this question because the necessary information was not found in the provided documents.\"\n",
    "\n",
    "    When answering, cite the **source file name** and **slide/page number** if available.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "773c2cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", user_input_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0557547",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt_template)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fb7b40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History table successfully created\n"
     ]
    }
   ],
   "source": [
    "history = ChatHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e5c89a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Statefully manage chat history ###\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InSessionMemoryHistory(session_id, db=history)\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37135288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_combined():\n",
    "    session_id = str(uuid.uuid4())[:8]\n",
    "    print(f\"\\nSession ID: {session_id}\")\n",
    "\n",
    "    print(f\"\\nModel {MODEL_NAME} has been initiated with memory. Please feel free to ask questions or type 'exit' to quit.\")\n",
    "    try:\n",
    "        while True:\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "                print(\"Session ended. Have a good day.\")\n",
    "                break\n",
    "\n",
    "            response = conversational_rag_chain.invoke(\n",
    "                {\"input\": user_input},\n",
    "                config={\"configurable\": {\"session_id\": session_id}},\n",
    "            )\n",
    "            print(f\"LLM: {response['answer']}\\n\")\n",
    "\n",
    "            # Note: The memory is managed by the chain via get_session_history\n",
    "            # So you don't need to manually add messages here\n",
    "    finally:\n",
    "        history.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0affec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Session ID: 80d2313e\n",
      "\n",
      "Model llama3.2 has been initiated with memory. Please feel free to ask questions or type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ProgrammingError(\"Error binding parameter 4: type 'list' is not supported\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Inserting message:\n",
      "  session_id: <class 'str'> 80d2313e\n",
      "  role: <class 'str'> human\n",
      "  turn_number: <class 'int'> 1\n",
      "  message: <class 'list'> [HumanMessage(content='Explain transformers', additional_kwargs={}, response_metadata={}), AIMessage(content='I can provide an explanation of transformers based on the provided context.\\n\\nA transformer is a practical application of magnetically coupled coils. It transfers energy from one coil to another by using a common magnetic core to improve coupling. The primary purpose of a transformer is to transfer energy while providing electrical isolation between the source and load, as well as changing voltage and current levels.\\n\\nThe basic principle of a transformer can be understood by considering two coils wound on opposite sides of a magnetic core, as shown in figure 6-6. When a sinusoidal voltage source drives the primary coil, it produces a sinusoidal magnetic flux that passes through both coils. This results in an induced voltage in the secondary coil.\\n\\nThe ratio of the voltages in the primary and secondary coils is determined by the ratio of the number of turns on each winding, as shown in equation 6-7: v1/v2 ≈ N1/N2. By changing the ratio of turns, transformers can be used to step-up or step-down voltages.\\n\\nTransformers are typically made with a magnetic core, which can be made from magnetically soft ferrites for high-frequency applications or iron alloys like silicon steel for power frequencies. The cores are designed to minimize eddy currents, and small transformers often use the shell-type construction, while larger ones may use toroidal constructions.\\n\\nIn addition to their primary function of voltage transformation, transformers have specialized applications such as instrument transformers (current and voltage transformers) used in measurement systems. These transformers typically employ toroidal constructions with high-quality core materials.\\n\\nOverall, transformers are essential components in electrical power transmission and distribution, as well as electronic equipment, where they enable efficient energy transfer and voltage transformation.\\n\\n**Source File Name:** Electrical Machines and Systems\\n**Slide/Page Number:** No specific reference provided', additional_kwargs={}, response_metadata={})]\n",
      "  timestamp: <class 'str'> 2025-06-18 18:10:07\n",
      "LLM: I can provide an explanation of transformers based on the provided context.\n",
      "\n",
      "A transformer is a practical application of magnetically coupled coils. It transfers energy from one coil to another by using a common magnetic core to improve coupling. The primary purpose of a transformer is to transfer energy while providing electrical isolation between the source and load, as well as changing voltage and current levels.\n",
      "\n",
      "The basic principle of a transformer can be understood by considering two coils wound on opposite sides of a magnetic core, as shown in figure 6-6. When a sinusoidal voltage source drives the primary coil, it produces a sinusoidal magnetic flux that passes through both coils. This results in an induced voltage in the secondary coil.\n",
      "\n",
      "The ratio of the voltages in the primary and secondary coils is determined by the ratio of the number of turns on each winding, as shown in equation 6-7: v1/v2 ≈ N1/N2. By changing the ratio of turns, transformers can be used to step-up or step-down voltages.\n",
      "\n",
      "Transformers are typically made with a magnetic core, which can be made from magnetically soft ferrites for high-frequency applications or iron alloys like silicon steel for power frequencies. The cores are designed to minimize eddy currents, and small transformers often use the shell-type construction, while larger ones may use toroidal constructions.\n",
      "\n",
      "In addition to their primary function of voltage transformation, transformers have specialized applications such as instrument transformers (current and voltage transformers) used in measurement systems. These transformers typically employ toroidal constructions with high-quality core materials.\n",
      "\n",
      "Overall, transformers are essential components in electrical power transmission and distribution, as well as electronic equipment, where they enable efficient energy transfer and voltage transformation.\n",
      "\n",
      "**Source File Name:** Electrical Machines and Systems\n",
      "**Slide/Page Number:** No specific reference provided\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: ProgrammingError(\"Error binding parameter 4: type 'list' is not supported\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Inserting message:\n",
      "  session_id: <class 'str'> 80d2313e\n",
      "  role: <class 'str'> human\n",
      "  turn_number: <class 'int'> 2\n",
      "  message: <class 'list'> [HumanMessage(content='What materials are they made of?', additional_kwargs={}, response_metadata={}), AIMessage(content='The cores for high-frequency transformers are often made from magnetically soft ferrites, while power frequency transformer cores are typically made from an iron alloy such as silicon steel.\\n\\nAdditionally, small power transformers are commonly made with a shell-type construction, where the coils are wound on a laminated core. The center limb is twice the width of the outer limbs because it carries twice the flux.\\n\\nIn induction machines, the rotor conductors are placed in slots in a laminated steel core, and are made from materials such as aluminium bars, which are connected to short-circuiting aluminium rings known as end-rings.\\n\\nNo other information about specific materials is mentioned.', additional_kwargs={}, response_metadata={})]\n",
      "  timestamp: <class 'str'> 2025-06-18 18:10:33\n",
      "LLM: The cores for high-frequency transformers are often made from magnetically soft ferrites, while power frequency transformer cores are typically made from an iron alloy such as silicon steel.\n",
      "\n",
      "Additionally, small power transformers are commonly made with a shell-type construction, where the coils are wound on a laminated core. The center limb is twice the width of the outer limbs because it carries twice the flux.\n",
      "\n",
      "In induction machines, the rotor conductors are placed in slots in a laminated steel core, and are made from materials such as aluminium bars, which are connected to short-circuiting aluminium rings known as end-rings.\n",
      "\n",
      "No other information about specific materials is mentioned.\n",
      "\n",
      "Session ended. Have a good day.\n"
     ]
    }
   ],
   "source": [
    "pipeline_combined()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4433162d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "Cannot operate on a closed database.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mconversational_rag_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mExplain transformers?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconfigurable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msession_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mabc123\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/base.py:5430\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5425\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5428\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5429\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5431\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/base.py:5430\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5425\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5428\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5429\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5431\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/base.py:3045\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3043\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   3044\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3045\u001b[39m         input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3046\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3047\u001b[39m         input_ = context.run(step.invoke, input_, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/base.py:5430\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5425\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5428\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5429\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5431\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/passthrough.py:511\u001b[39m, in \u001b[36mRunnableAssign.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    506\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    509\u001b[39m     **kwargs: Any,\n\u001b[32m    510\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/base.py:1940\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1936\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1937\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1938\u001b[39m         output = cast(\n\u001b[32m   1939\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1941\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1942\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1946\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1947\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1948\u001b[39m         )\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1950\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/passthrough.py:497\u001b[39m, in \u001b[36mRunnableAssign._invoke\u001b[39m\u001b[34m(self, value, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m    492\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)  \u001b[38;5;66;03m# noqa: TRY004\u001b[39;00m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    496\u001b[39m     **value,\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m     **\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    502\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/base.py:3774\u001b[39m, in \u001b[36mRunnableParallel.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3769\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3770\u001b[39m         futures = [\n\u001b[32m   3771\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3772\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3773\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m3774\u001b[39m         output = \u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m   3775\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3776\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/base.py:3774\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   3769\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m   3770\u001b[39m         futures = [\n\u001b[32m   3771\u001b[39m             executor.submit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[32m   3772\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps.items()\n\u001b[32m   3773\u001b[39m         ]\n\u001b[32m-> \u001b[39m\u001b[32m3774\u001b[39m         output = {key: \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[32m   3775\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3776\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/base.py:3758\u001b[39m, in \u001b[36mRunnableParallel.invoke.<locals>._invoke_step\u001b[39m\u001b[34m(step, input_, config, key)\u001b[39m\n\u001b[32m   3752\u001b[39m child_config = patch_config(\n\u001b[32m   3753\u001b[39m     config,\n\u001b[32m   3754\u001b[39m     \u001b[38;5;66;03m# mark each step as a child run\u001b[39;00m\n\u001b[32m   3755\u001b[39m     callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmap:key:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m),\n\u001b[32m   3756\u001b[39m )\n\u001b[32m   3757\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m-> \u001b[39m\u001b[32m3758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m context.run(\n\u001b[32m   3759\u001b[39m         step.invoke,\n\u001b[32m   3760\u001b[39m         input_,\n\u001b[32m   3761\u001b[39m         child_config,\n\u001b[32m   3762\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/base.py:5430\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5425\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5428\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5429\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5431\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/base.py:4771\u001b[39m, in \u001b[36mRunnableLambda.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   4757\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[32m   4758\u001b[39m \n\u001b[32m   4759\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   4768\u001b[39m \u001b[33;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[32m   4769\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4770\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfunc\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m4771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4772\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4773\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4774\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4775\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4776\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4777\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4778\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/base.py:1940\u001b[39m, in \u001b[36mRunnable._call_with_config\u001b[39m\u001b[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[39m\n\u001b[32m   1936\u001b[39m     child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m   1937\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m   1938\u001b[39m         output = cast(\n\u001b[32m   1939\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOutput\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m-> \u001b[39m\u001b[32m1940\u001b[39m             \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1941\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1942\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1943\u001b[39m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1944\u001b[39m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1945\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1946\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1947\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1948\u001b[39m         )\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1950\u001b[39m     run_manager.on_chain_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/base.py:4629\u001b[39m, in \u001b[36mRunnableLambda._invoke\u001b[39m\u001b[34m(self, input_, run_manager, config, **kwargs)\u001b[39m\n\u001b[32m   4627\u001b[39m                 output = chunk\n\u001b[32m   4628\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4629\u001b[39m     output = \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4630\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   4631\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4632\u001b[39m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[32m   4633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/config.py:428\u001b[39m, in \u001b[36mcall_func_with_variable_args\u001b[39m\u001b[34m(func, input, config, run_manager, **kwargs)\u001b[39m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[32m    427\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m] = run_manager\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/LLM_Train/lib/python3.11/site-packages/langchain_core/runnables/history.py:514\u001b[39m, in \u001b[36mRunnableWithMessageHistory._enter_history\u001b[39m\u001b[34m(self, value, config)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_enter_history\u001b[39m(\u001b[38;5;28mself\u001b[39m, value: Any, config: RunnableConfig) -> \u001b[38;5;28mlist\u001b[39m[BaseMessage]:\n\u001b[32m    513\u001b[39m     hist: BaseChatMessageHistory = config[\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage_history\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m514\u001b[39m     messages = \u001b[43mhist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessages\u001b[49m.copy()\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.history_messages_key:\n\u001b[32m    517\u001b[39m         \u001b[38;5;66;03m# return all messages\u001b[39;00m\n\u001b[32m    518\u001b[39m         input_val = (\n\u001b[32m    519\u001b[39m             value \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.input_messages_key \u001b[38;5;28;01melse\u001b[39;00m value[\u001b[38;5;28mself\u001b[39m.input_messages_key]\n\u001b[32m    520\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Year 4/RAG-Project/chat_memory.py:82\u001b[39m, in \u001b[36mInSessionMemoryHistory.messages\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmessages\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_session_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Year 4/RAG-Project/chat_memory.py:54\u001b[39m, in \u001b[36mChatHistory.load_session_messages\u001b[39m\u001b[34m(self, session_id)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_session_messages\u001b[39m(\u001b[38;5;28mself\u001b[39m, session_id):\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lock:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         cursor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m         cursor.execute(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[33m        SELECT role, message FROM History\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[33m        WHERE session_id = ?\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[33m        ORDER BY id ASC\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[33m        \u001b[39m\u001b[33m\"\"\"\u001b[39m, (session_id,))\n\u001b[32m     60\u001b[39m         rows = cursor.fetchall()\n",
      "\u001b[31mProgrammingError\u001b[39m: Cannot operate on a closed database."
     ]
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"Explain transformers?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec03a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_session_history(\"abc123\").messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_Train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

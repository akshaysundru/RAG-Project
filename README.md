# RAG-Project
Experimenting with Retrieval Augmented Generation, using various Ollama chatbots

To run the code as is make sure you have the following dependencies downloaded. This will be updated the further I get.

- Ollama
- Miniconda
- ipykernel
- Python + assoc. libraries

Currently for prototyping I will be using Llama 3.2, as it appears to be a model that runs on my Macbook Pro M3 fine, though if i get a PC set up I would like to run the Llama 4 models.

I currently have successfully run Llama 3.2 locally with an example output attached on the repo under the RAG_notebook.ipynb file, next step is to compile some research on RAG and build a simple pipeline. I will be uploading a folder with unit readers from different units.